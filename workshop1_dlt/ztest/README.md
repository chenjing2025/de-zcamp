# ğŸš´â€â™‚ï¸ End-to-End Data Pipeline for Santander Bike Rentals

## ğŸ“‘ Table of Contents

* [Objectives](#objectives)
* [Dataset](#dataset)
* [Tech Stack](#tech-stack)
* [Pipeline Architecture](#pipeline-architecture)
* [Dashboard Features](#dashboard-features)
* [Repository Structure](#repository-structure)
* [Deployment Guide](#deployment-guide)
* [Future Enhancements](#future-enhancements)
* [Contributors](#contributors)

## ğŸ“Œ Overview
This project builds an end-to-end data pipeline to process and visualize Santander bicycle rental data in London. It integrates cloud-based storage, data transformation, and dashboard visualization.

## ğŸ¯ Objectives
Ingest & Store ğŸš€ - Fetch and store raw data in a data lake (Google Cloud Storage).

Process & Transform ğŸ”„ - Move data to BigQuery and clean it for analysis.

Visualize & Analyze ğŸ“Š - Build a Looker Studio dashboard with key insights.

## ğŸ“‚ Dataset
Source: TfL Cycling Open Data

Content: Time-series data on Santander bicycle rentals across London.

## âš™ï¸ Tech Stack
Cloud Platform: Google Cloud Platform (GCP) â˜ï¸

Orchestration: Apache Airflow (Dockerized) ğŸ”„

Data Warehouse: BigQuery ğŸ›ï¸

Infrastructure: Terraform ğŸ—ï¸

Visualization: Looker Studio ğŸ“Š

## ğŸ› ï¸ Pipeline Architecture

[Data Source] â†’ [GCS] â†’ [Airflow DAGs] â†’ [BigQuery] â†’ [Looker Studio]
Ingestion: Collects raw data and stores it in GCS.

Processing: Moves data from GCS to BigQuery.

Transformation: Cleans and structures data for analytics.

Visualization: Displays insights via Looker Studio.

## ğŸ“Š Dashboard Features
Categorical Data Distribution ğŸ“Œ - Breakdown of key categorical variables.

Temporal Trends â³ - Analysis of rental trends over time.

## ğŸ—ï¸ Repository Structure
```
ğŸ“‚ airflow/
 â”œâ”€â”€ ğŸ“‚ dags/               # Airflow DAGs
 â”‚    â”œâ”€â”€ dag1.py
 â”‚    â”œâ”€â”€ dag2.py
 â”‚    â”œâ”€â”€ dag3.py
 â”œâ”€â”€ ğŸ“‚ sql/                # SQL transformation scripts
 â”‚    â”œâ”€â”€ query1.sql
 â”‚    â”œâ”€â”€ query2.sql
 â”œâ”€â”€ ğŸ“ Dockerfile           # Airflow containerization
 â”œâ”€â”€ ğŸ“ docker-compose.yml   # Docker setup
 â”œâ”€â”€ ğŸ“ README.md            # Project documentation
```

## ğŸš€ Deployment Guide
Set up GCP resources using Terraform to provision the necessary infrastructure.

Deploy Airflow DAGs to automate the data ingestion, storage in Google Cloud Storage (GCS), and processing into BigQuery.

Run data transformations in BigQuery, optionally using dbt.

Create a Looker Studio Dashboard using the processed data for visualization.

## ğŸ”® Future Enhancements
Automate transformations using dbt.

Add real-time data processing.

Expand dashboard insights.

ğŸ‘¥ Contributors
Your Name
