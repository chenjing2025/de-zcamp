{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19f8ed5-e8e6-4d9c-ac13-86465b233404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)  # Should print 3.5.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19689ec-04db-4a80-a0ab-dbb1d630b95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.9.5\n"
     ]
    }
   ],
   "source": [
    "import py4j\n",
    "print(py4j.__version__)  # Should print 0.10.9.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59971b42-3df7-4196-bff1-7d92a468c1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/03 22:00:05 WARN Utils: Your hostname, DESKTOP-RKINDGJ resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/03 22:00:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/03/03 22:00:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "+-----------+\n",
      "|test_column|\n",
      "+-----------+\n",
      "|          1|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a new Spark session (use it directly in case thereâ€™s a session issue)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark SQL Test\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Test with a simple SQL query\n",
    "spark.sql(\"SELECT 1 as test_column\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86ad77-39cf-43c3-b182-f60145313261",
   "metadata": {},
   "source": [
    "## Question 3: Count records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045da5f-1ed7-447c-baa0-f99a03e28781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Parquet file into a DataFrame\n",
    "df_parquet = spark.read.parquet(\"yellow_tripdata_2024-10.parquet\")\n",
    "\n",
    "# Print the schema to see the columns\n",
    "df_parquet.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61f05fd-de60-4ac3-bec9-ac24a5636661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|trip_count|\n",
      "+----------+\n",
      "|    110732|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the Parquet file (yellow_tripdata_2024-10.parquet)\n",
    "df_parquet = spark.read.parquet(\"yellow_tripdata_2024-10.parquet\")\n",
    "\n",
    "# Load the CSV file (taxi_zone_lookup.csv)\n",
    "df_csv = spark.read.option(\"header\", \"true\").csv(\"taxi_zone_lookup.csv\")\n",
    "\n",
    "# Register DataFrames as SQL temporary views\n",
    "df_parquet.createOrReplaceTempView(\"yellow_taxi_trips\")\n",
    "df_csv.createOrReplaceTempView(\"taxi_zone_lookup\")\n",
    "\n",
    "# Run the SQL query to count records for October 15th\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) AS trip_count\n",
    "    FROM yellow_taxi_trips\n",
    "    WHERE DATE(tpep_pickup_datetime) = '2024-10-15'\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f777fa-061a-4867-a66a-5175e9ab1e66",
   "metadata": {},
   "source": [
    "## Question 4: Longest trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c391a2ad-dba6-4f7a-9e67-ed59764be0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|longest_trip_hours|\n",
      "+------------------+\n",
      "|162.61777777777777|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the longest trip duration in hours\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT MAX((UNIX_TIMESTAMP(tpep_dropoff_datetime) - UNIX_TIMESTAMP(tpep_pickup_datetime)) / 3600) AS longest_trip_hours\n",
    "    FROM yellow_taxi_trips\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd89002-9444-4b76-a791-e3c691ff0304",
   "metadata": {},
   "source": [
    "## Question 6: Least frequent pickup location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9589185-aba2-4bc2-9bc5-7d1f300ec876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+------------+\n",
      "|Zone                                         |pickup_count|\n",
      "+---------------------------------------------+------------+\n",
      "|Governor's Island/Ellis Island/Liberty Island|1           |\n",
      "+---------------------------------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"\n",
    "    SELECT tz.Zone, COUNT(*) AS pickup_count\n",
    "    FROM yellow_taxi_trips yt\n",
    "    JOIN taxi_zone_lookup tz\n",
    "    ON yt.PULocationID = tz.LocationID\n",
    "    GROUP BY tz.Zone\n",
    "    ORDER BY pickup_count ASC\n",
    "    LIMIT 1\n",
    "\"\"\")\n",
    "\n",
    "# Show the result\n",
    "# result.show()\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f55d3-9d6a-4188-827c-9ce2917a6365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
